{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28773e9-a9b1-45a0-963c-1f90ab7c40cb",
   "metadata": {},
   "source": [
    "## Using Autograd in PyTorch to Solve a Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec27624-b20a-4bfd-b408-18cb564a7ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "torch.Size([3])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# create a number vector as a tensor that can be used as a variable\n",
    "import torch\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d52801d-744f-459c-85f0-e8089a162985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], requires_grad=True)\n",
      "torch.Size([3])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Set up a tensor to support differentiation\n",
    "# a tensor of floating point values is created \n",
    "# It is required because differentiation requires floating points, not integers\n",
    "x = torch.tensor([1., 2., 3.], requires_grad=True) \n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c76f097-fe09-4957-920c-187b98582eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor(3.6000, requires_grad=True)\n",
      "y = tensor(12.9600, grad_fn=<MulBackward0>)\n",
      "x.grad = tensor(7.2000)\n"
     ]
    }
   ],
   "source": [
    "# get the derivative of x in the form of a tensor\n",
    "x = torch.tensor(3.6, requires_grad=True) \n",
    "y=x*x\n",
    "y.backward()\n",
    "print(\"x =\", x)\n",
    "print(\"y =\", y)\n",
    "print(\"x.grad =\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3757f15-266a-41a2-8946-7d974b9dc77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2\n",
      "1 x + 2 x + 3\n"
     ]
    }
   ],
   "source": [
    "# build a random polynomial in numpy\n",
    "import numpy as np\n",
    "polynomial = np.poly1d([1, 2, 3])\n",
    "print(polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd278fad-7eb1-431e-81a2-0e7e87534fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.25\n"
     ]
    }
   ],
   "source": [
    "# use the polynomial as a function\n",
    "print(polynomial(1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f73b76e-f335-4405-b237-9974d7e7863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a number of samples from this function using NumPy\n",
    "N = 20 # number of samples\n",
    "# Generate random samples roughly between -10 to +10\n",
    "X = np.random.randn(N,1) * 5\n",
    "Y = polynomial(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e120c41c-bae3-4278-be54-e48f1fed730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.57594547e+01  6.76457351e+00  1.00000000e+00]\n",
      " [ 1.29655260e+01  3.60076742e+00  1.00000000e+00]\n",
      " [ 2.35134331e+00  1.53340905e+00  1.00000000e+00]\n",
      " [ 9.42143619e+01 -9.70640829e+00  1.00000000e+00]\n",
      " [ 1.82703899e+01  4.27438767e+00  1.00000000e+00]\n",
      " [ 3.01218200e+01  5.48833490e+00  1.00000000e+00]\n",
      " [ 8.40333330e+01  9.16696967e+00  1.00000000e+00]\n",
      " [ 9.76666517e+00 -3.12516642e+00  1.00000000e+00]\n",
      " [ 7.67137033e+00 -2.76972387e+00  1.00000000e+00]\n",
      " [ 3.39243606e+01  5.82446225e+00  1.00000000e+00]\n",
      " [ 5.73529688e-02 -2.39484799e-01  1.00000000e+00]\n",
      " [ 3.17514686e+01  5.63484415e+00  1.00000000e+00]\n",
      " [ 3.64399643e+00  1.90892547e+00  1.00000000e+00]\n",
      " [ 1.68687764e+02  1.29879854e+01  1.00000000e+00]\n",
      " [ 1.37417485e+02  1.17225204e+01  1.00000000e+00]\n",
      " [ 1.91185906e+01 -4.37248105e+00  1.00000000e+00]\n",
      " [ 3.86324659e+01 -6.21550207e+00  1.00000000e+00]\n",
      " [ 4.09241599e+01 -6.39719938e+00  1.00000000e+00]\n",
      " [ 2.51993148e+01 -5.01989191e+00  1.00000000e+00]\n",
      " [ 5.90639674e+01 -7.68530854e+00  1.00000000e+00]]\n",
      "tensor([[ 1.0260],\n",
      "        [-0.0461],\n",
      "        [-1.2620]], requires_grad=True)\n",
      "tensor([[1.0005],\n",
      "        [1.9987],\n",
      "        [2.9609]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Assume samples X and Y are prepared elsewhere \n",
    "XX = np.hstack([X*X, X, np.ones_like(X)])\n",
    "print(XX)\n",
    "w = torch.randn(3, 1, requires_grad=True) # the 3 coefficients \n",
    "x = torch.tensor(XX, dtype=torch.float32) # input sample\n",
    "y = torch.tensor(Y, dtype=torch.float32) # output sample \n",
    "optimizer = torch.optim.NAdam([w], lr=0.01)\n",
    "print(w)\n",
    "for _ in range(1000): \n",
    "     y_pred = x @ w\n",
    "     mse = torch.mean(torch.square(y - y_pred))\n",
    "     optimizer.zero_grad()\n",
    "     mse.backward()\n",
    "     optimizer.step()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c65701e-4a7a-46c5-b520-983fe14fc1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6253],\n",
      "        [-0.1860],\n",
      "        [ 0.2265]], requires_grad=True)\n",
      "tensor([[1.0013],\n",
      "        [2.0027],\n",
      "        [2.9445]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# the complete code\n",
    "polynomial = np.poly1d([1, 2, 3]) \n",
    "N = 20 # number of samples\n",
    "# Generate random samples roughly between -10 to +10\n",
    "X = np.random.randn(N,1) * 5\n",
    "Y = polynomial(X)\n",
    "# Prepare input as an array of shape (N,3)\n",
    "XX = np.hstack([X*X, X, np.ones_like(X)])\n",
    "# Prepare tensors\n",
    "w = torch.randn(3, 1, requires_grad=True) # the 3 coefficients \n",
    "x = torch.tensor(XX, dtype=torch.float32) # input sample\n",
    "y = torch.tensor(Y, dtype=torch.float32)\n",
    "optimizer = torch.optim.NAdam([w], lr=0.01)\n",
    "print(w)\n",
    "# Run optimizer\n",
    "# output sample\n",
    "for _ in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = x @ w\n",
    "    mse = torch.mean(torch.square(y - y_pred)) \n",
    "    # derive the gradient, i.e., the rate of change of the mean\n",
    "    # square error with respect to the coefficients w \n",
    "    # using the backward() function\n",
    "    mse.backward()\n",
    "    optimizer.step()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a194e15-3989-4d91-8074-6090e5bab7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
